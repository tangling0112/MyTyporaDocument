# PathWays

## 常见的分布式深度学习方法

![image-20220509103319943](C:\Users\Administrator\Desktop\Typora文档\深度学习\Pathways.assets\image-20220509103319943.png)

### 整模型梯度累加方案

- 基本步骤
  - 两个主机都各自作为自己的管理者，都拿到我们整个模型
  - 两个主机在第`k`次迭代开始时有相同的模型参数
  - 两个主机分别拿到一定量数据
  - 主机分别对模型进行前向传播与反向传播
  - 当第`k`次迭代的反向传播完成时,两个主机阻塞并通信交流梯度信息,并通过梯度累加方法对两个主机上的模型进行更新
  - 在`k+1`次开始时两个主机上的模型参数相同,都是通过梯度累加方法更新了的.
  - 重复上述步骤

- 模型架构
  - ![image-20220509103106088](C:\Users\Administrator\Desktop\Typora文档\深度学习\Pathways.assets\image-20220509103106088.png)

#### 方案而二

> - 模型具备一个独有的中央控制器`Ctrlr`其会把我们需要训练的模型编译好.
> - 模型具备多个训练器,他们会接收中央控制器`Ctrlr`发送到编译好的模型

- 基本步骤
  - 中央控制器`Ctrlr`将编译好的模型发送给所有的训练器
  - 训练器对模型进行前向传播与反向传播
  - 所有训练器阻塞,将计算得到的梯度互相传递,然后进行梯度累加的模型更新
  - 更新的参数发送给我们的中央控制器,中央控制器对模型进行梯度累加更新
  - 重复上述步骤
- 基本结构
  - ![image-20220509103247469](C:\Users\Administrator\Desktop\Typora文档\深度学习\Pathways.assets\image-20220509103247469.png)

### 模型分层方案

- 基本步骤

- 模型架构
  - ![image-20220509103307338](C:\Users\Administrator\Desktop\Typora文档\深度学习\Pathways.assets\image-20220509103307338.png)